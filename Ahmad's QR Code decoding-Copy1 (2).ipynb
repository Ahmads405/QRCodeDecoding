{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5e30ba80e34d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhough_circle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhough_circle_peaks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcanny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcircle_perimeter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/skimage/transform/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mprobabilistic_hough_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhough_circle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               hough_circle_peaks, hough_ellipse)\n\u001b[0;32m----> 5\u001b[0;31m from .radon_transform import (radon, iradon, iradon_sart,\n\u001b[0m\u001b[1;32m      6\u001b[0m                               order_angles_golden_ratio)\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfinite_radon_transform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifrt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/skimage/transform/radon_transform.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterp1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgolden_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_warps\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_radon_transform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msart_projection_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfftmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          ProjectiveTransform, _to_ndimage_mode)\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_warps_cy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_warp_fast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mblock_reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m from .._shared.utils import (get_bound_method_class, safe_as_int, warn,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/skimage/measure/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimple_metrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompare_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_nrmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_psnr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_structural_similarity\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompare_ssim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_polygon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapproximate_polygon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdivide_polygon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpnpoly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpoints_in_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_points_in_poly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m from ._moments import (moments, moments_central, moments_coords,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/skimage/measure/_polygon.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapproximate_polygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/signal/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mspectral\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwavelets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_peak_finding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwindows\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_window\u001b[0m  \u001b[0;31m# keep this one in signal namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/signal/_peak_finding.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavelets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcwt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mricker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscoreatpercentile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m from ._peak_finding_utils import (\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/stats/distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                     rv_frozen)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_discrete_distns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m \u001b[0mgenhalflogistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenhalflogistic_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'genhalflogistic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, momtype, a, b, xtol, badvalue, name, longname, shapes, extradoc, seed)\u001b[0m\n\u001b[1;32m   1574\u001b[0m                  shapes=None, extradoc=None, seed=None):\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv_continuous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m         \u001b[0;31m# save the ctor parameters, cf generic freeze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;31m# figure out if _stats signature has 'moments' keyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0msign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m         self._stats_has_moments = ((sign[2] is not None) or\n\u001b[1;32m    593\u001b[0m                                    ('moments' in sign[0]))\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36mgetargspec_no_self\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mpython\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0munder\u001b[0m \u001b[0mpython\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \"\"\"\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         args = [\n\u001b[1;32m    300\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2831\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2832\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0;32m-> 2833\u001b[0;31m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[1;32m   2834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2835\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2215\u001b[0m             \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m             \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m             sigcls=sigcls)\n\u001b[0m\u001b[1;32m   2218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2282\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0;32m-> 2154\u001b[0;31m                                     kind=_POSITIONAL_OR_KEYWORD))\n\u001b[0m\u001b[1;32m   2155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m     \u001b[0;31m# ... w/ defaults.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2469\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ParameterKind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2470\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'value {kind!r} is not a valid Parameter.kind'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/enum.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \"\"\"Either returns an existing member, or creates a new enum class.\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from skimage import data, color\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import circle_perimeter\n",
    "from skimage.util import img_as_ubyte\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "#from pyzbar import pyzbar\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import exposure\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from skimage.io import imread, imsave\n",
    "from skimage import exposure\n",
    "#from skimage.exposure import match_histograms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from skimage import data, color\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import circle_perimeter\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "import zbar\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import exposure\n",
    "import os\n",
    "from scipy.ndimage import rotate\n",
    "#from pyzbar.pyzbar import decode\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "np.set_printoptions(threshold=np. inf)\n",
    "#from BasicDeblurAhmad import BlindDeblur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_match_qr(full_image,template_passed):\n",
    "    img2 = full_image.copy()\n",
    "    template = cv2.imread(template_passed,0)\n",
    "    print(type(template))\n",
    "    w, h = template.shape[::-1]\n",
    "    # All the 6 methods for comparison in a list\n",
    "    methods = [ 'cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED' , 'cv2.TM_CCORR',\n",
    "                'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "    print('template shape is ',template.shape)\n",
    "    print('img2 shape is ', img2.shape)\n",
    "    #template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY) #template i uploaded only has 1 dimension. fix this. that is why we error\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    for meth in methods:\n",
    "        img = img2.copy()\n",
    "        method = eval(meth)\n",
    "        # Apply template Matching\n",
    "        img.astype(np.uint8)\n",
    "        template.astype(np.uint8)\n",
    "\n",
    "        res = cv2.matchTemplate(img,template,method)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        \n",
    "        cv2.rectangle(img,top_left, bottom_right, 255, 20)\n",
    "        plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "        plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "        plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "        plt.suptitle(meth)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so loading in the specific csv to the image works now. work on making sure it places the right square\n",
    "def CorrectBoxCropping(image_folder,folder_location_csv,deblurred_images):\n",
    "    detected_slice_count=0\n",
    "    im_path = sorted(glob.glob(image_folder)) #path to the jpg images folder\n",
    "\n",
    "    detection_count=0 #detection_count keeps track of \n",
    "    csv_of_qr=np.array([[0,0]]) #cvs of qr is where we store csv first column is name of image, second column is decoded message\n",
    "    csv_of_qr.shape=(1,2)\n",
    "    for im in (im_path): #here is where we will loop for each photo\n",
    "        #this part below will be for finding where the box lies\n",
    "        \n",
    "        \n",
    "        \n",
    "        my_im = im.split('/')[-1]\n",
    "        name_of_image_csv=my_im.split('.')[0]+'.csv'\n",
    "    \n",
    "        print('Loading image: ',my_im)\n",
    " \n",
    "\n",
    "        #im = Image.open(im)\n",
    "        im = cv2.imread(im)[...,::-1]\n",
    "        image_1 = np.array(im) \n",
    "        height_of_im,width_of_im,color_of_im=image_1.shape\n",
    "        \n",
    "        #this code below finds where the box should be and crops it out\n",
    "        increment_counter=0\n",
    "\n",
    "        \n",
    "        csv_names=os.listdir(folder_location_csv)\n",
    "        #this checks if a label exists. If it doesn't we skip\n",
    "        if(name_of_image_csv in csv_names):\n",
    "            labels_csv =pd.read_csv(folder_location_csv+name_of_image_csv, sep=',',header=None)\n",
    "        else:\n",
    "            continue\n",
    "        col_we_looking_at=labels_csv[0].values[0]\n",
    "        my_split=col_we_looking_at.split()  #my split is a list of each entry in the specific column which is a string. it turns string into a list\n",
    "        x_center=float(my_split[1])*width_of_im\n",
    "        y_center=float(my_split[2])*height_of_im\n",
    "        width=float(my_split[3])*width_of_im\n",
    "        height=float(my_split[4])*width_of_im\n",
    "        x_start=int(x_center-.5*width)\n",
    "        y_start=int(y_center-.5*height)\n",
    "        x_end=int(x_center+.5*width)\n",
    "        y_end=int(y_center+.5*height)\n",
    "        #cv2.rectangle(image_1,(x_start, y_start),\n",
    "                      #(x_end, y_end),\n",
    "                      #(220, 0, 0), 50)\n",
    "        \n",
    "        #this code below will crop the suit out correctly\n",
    "        \n",
    "        buffer=0\n",
    "        xs = max(x_start-buffer,0)\n",
    "        ys = max(y_start-buffer,0)\n",
    "        xe = min(x_end+buffer,image_1.shape[1])\n",
    "        ye = min(y_end+buffer,image_1.shape[0])\n",
    "\n",
    "        new_image = np.array(image_1)[ys:ye,xs:xe,:] #this line does cropping\n",
    "  \n",
    "        # the lines below blur the image but are unneeded now\n",
    "    \n",
    "    \n",
    "        #new_image_gaussian_blur= cv2.cvtColor(new_image,cv2.COLOR_BGR2GRAY)\n",
    "        #new_image_gaussian_blur = gaussian_filter(new_image_gaussian_blur, sigma=4)\n",
    "        #plt.title('gaussian blurred image')\n",
    "        #plt.imshow(new_image_gaussian_blur,cmap='gray')\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "        #contrasting part ends\n",
    "        \n",
    "        '''\n",
    "        This part below handles the decrypting\n",
    "        '''\n",
    "        did_it_detect_in_rotate=0\n",
    "        it_decoded=False\n",
    "        for i in range(8): #I used 8 since I want to rotate the image 8 times by 45 degrees so it scans thw qr code upright\n",
    "            new_image_rotated=new_image\n",
    "            new_image_rotated= cv2.cvtColor(new_image_rotated,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            new_image_rotated=rotate(new_image_rotated,angle=45*i)\n",
    "            try:\n",
    "                #qrCodeDetector = cv2.QRCodeDetector()\n",
    "                #decodedText, points, _ = qrCodeDetector.detectAndDecode(new_image_rotated)\n",
    "                zbar_scanner = zbar.Scanner()\n",
    "                decodedText = zbar_scanner.scan(new_image_rotated)\n",
    "                #print('unenhanced decoded text is',decodedText)\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "            if len(decodedText) > 0:\n",
    "                print('Text Decoded!')\n",
    "                plt.title('qr code detected without any modification')\n",
    "                plt.imshow(new_image_rotated,cmap='gray')\n",
    "                plt.show()                \n",
    "                detection_count +=1\n",
    "                did_it_detect_in_rotate=1\n",
    "                #add to csv file\n",
    "                csv_of_qr=np.vstack((csv_of_qr,np.array([my_im,decodedText]))) #this adds it to the csv\n",
    "                it_decoded=True\n",
    "                break\n",
    "        if(did_it_detect_in_rotate==1):\n",
    "            continue\n",
    "        \n",
    "        print('Unenhanced images detected: ',detection_count)\n",
    "        increment_counter+=1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #this if statement below does the deblurred try, deblurred images should already be cropped and deblurred beforehand\n",
    "        if (it_decoded!=True):\n",
    "            did_it_detect_in_rotate=0\n",
    "            it_decoded=False\n",
    "            if '*.JPG' in deblurred_images:\n",
    "                deblurred_images=deblurred_images.replace('*.JPG','')\n",
    "            deblurred_image=deblurred_images+my_im\n",
    "            deblurred_image_array = cv2.imread(deblurred_image)[...,::-1]  \n",
    "\n",
    "            plt.title('deblurred image is')\n",
    "            plt.imshow(deblurred_image_array,cmap='gray')\n",
    "            plt.show()\n",
    "            for i in range(8): #again we rotate like before and try to read it\n",
    "                deblurred_image_rotated_array=deblurred_image_array\n",
    "                deblurred_image_rotated_array= cv2.cvtColor(deblurred_image_rotated_array,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                deblurred_image_rotated_array=rotate(deblurred_image_rotated_array,angle=45*i)\n",
    "                try:\n",
    "                    #qrCodeDetector = cv2.QRCodeDetector()\n",
    "                    #decodedText, points, _ = qrCodeDetector.detectAndDecode(new_image_rotated)\n",
    "                    zbar_scanner = zbar.Scanner()\n",
    "                    decodedText = zbar_scanner.scan(deblurred_image_rotated_array)\n",
    "                    #print('unenhanced decoded text is',decodedText)\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "                if len(decodedText) > 0:\n",
    "                    print('Text Decoded!')\n",
    "                    plt.title('deblurred required for qr code to be read')\n",
    "                    plt.imshow(deblurred_image_rotated_array,cmap='gray')\n",
    "                    plt.show()                \n",
    "                    #print('decodedText is',decodedText)\n",
    "                    detection_count +=1\n",
    "                    #detected_slice_count+=1\n",
    "                    did_it_detect_in_rotate=1\n",
    "                    #add to csv file\n",
    "                    csv_of_qr=np.vstack((csv_of_qr,np.array([my_im,decodedText])))\n",
    "                    it_decoded=True\n",
    "                    break\n",
    "        if(did_it_detect_in_rotate==1):\n",
    "            continue\n",
    "        #my_im is the name and .jpg\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "     #this part tries out basic deblurring   \n",
    "        if (it_decoded!=True):\n",
    "            did_it_detect_in_rotate=0\n",
    "            it_decoded=False\n",
    "            cropped_images='cropped_folder/*.JPG'\n",
    "            if '*.JPG' in cropped_images:\n",
    "                cropped_images=cropped_images.replace('*.JPG','')\n",
    "            cropped_image=cropped_images+my_im\n",
    "            cropped_image_array = cv2.imread(cropped_image)[...,::-1]  \n",
    "\n",
    "            cropped_image_array=BlindDeblur(cropped_image_array)\n",
    "            for i in range(8):\n",
    "                cropped_image_rotated_array=cropped_image_array\n",
    "                #cropped_image_rotated_array= cv2.cvtColor(cropped_image_rotated_array,cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "                cropped_image_rotated_array=rotate(cropped_image_rotated_array,angle=45*i)\n",
    "\n",
    "                \n",
    "\n",
    "                try:\n",
    "                    #qrCodeDetector = cv2.QRCodeDetector()\n",
    "                    #decodedText, points, _ = qrCodeDetector.detectAndDecode(new_image_rotated)\n",
    "                    zbar_scanner = zbar.Scanner()\n",
    "                    decodedText = zbar_scanner.scan(cropped_image_rotated_array)\n",
    "                    #print('unenhanced decoded text is',decodedText)\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "                if len(decodedText) > 0:\n",
    "                    print('Text Decoded!')\n",
    "                    plt.title('qr code detected in Blinddeblurred')\n",
    "                    plt.imshow(cropped_image_rotated_array,cmap='gray')\n",
    "                    plt.show()                \n",
    "                    #print('decodedText is',decodedText)\n",
    "                    detection_count +=1\n",
    "                    #detected_slice_count+=1\n",
    "                    did_it_detect_in_rotate=1\n",
    "                    #add to csv file\n",
    "                    csv_of_qr=np.vstack((csv_of_qr,np.array([my_im,decodedText])))\n",
    "                    it_decoded=True\n",
    "                    break\n",
    "        if(did_it_detect_in_rotate==1):\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        '''    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #this part below will try to detect rectangle and try to decode it\n",
    "        if (it_decoded!=True): \n",
    "            cropping_rectangle_return=RectangularDetection2(new_image)\n",
    "            print('cropping_rectangle_return is',cropping_rectangle_return)\n",
    "            if(cropping_rectangle_return!=0):\n",
    "                csv_of_qr=np.vstack((csv_of_qr,np.array([my_im,cropping_rectangle_return])))\n",
    "                detected_slice_count=detected_slice_count+1\n",
    "            print('Total Number of Slices Decoded',detected_slice_count)\n",
    "            #template_match_qr(new_image,'Datasets/template qr code/DSC_1032_cropped.jpg')\n",
    "            #RectangularDetection(new_image,'Datasets/template qr code/DSC_1032_cropped.jpg')\n",
    "    print('Total Number of images Decoded',detected_slice_count+detection_count)\n",
    "    print('final csv is',csv_of_qr)  \n",
    "    print('final csv shape is',csv_of_qr)\n",
    "    return csv_of_qr\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RectangularDetection2(full_image_array):\n",
    "    image=full_image_array\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY) \n",
    "    close=gray\n",
    "    num_rows_close,num_cols_close=close.shape\n",
    "    percentile=np.percentile(close,80) #60 works best here\n",
    "    print('all colors below this value turn black to help detect white',percentile)\n",
    "    \n",
    "    for i in range(num_rows_close):\n",
    "        for j in range(num_cols_close):\n",
    "            if(close[i,j]<percentile):\n",
    "                close[i,j]=0\n",
    "    plt.title('image after turning white and black is ')\n",
    "    plt.imshow(close,cmap='gray')\n",
    "    plt.show()\n",
    "    #thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,51,9)\n",
    "    #uncomment above line for thresh\n",
    "    # Fill rectangular contours\n",
    "    cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) #change to thresh, or close for normal\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        cv2.drawContours(close, [c], -1, (255,255,255), -1) #change this to thresh too, or close for normal\n",
    "\n",
    "    # Morph open\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "    opening = cv2.morphologyEx(close, cv2.MORPH_OPEN, kernel, iterations=4) #change to thresh, originally 4 iterations, used 1 for numbers i sent joe\n",
    "    \n",
    "    # Draw rectangles\n",
    "    cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) #change to opening for the thresh thing\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    plt.title('image after image processing is')\n",
    "    plt.imshow(opening,cmap='gray')\n",
    "    plt.show()\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if(y>.2*num_cols_close and w>.2*num_rows_close):\n",
    "            \n",
    "            #this takes the box and performs qr code detection\n",
    "            sliced_image=full_image_array[y:y+h,x:x+w]\n",
    "            #sliced_image=BlindDeblur(sliced_image)\n",
    "            plt.title('rectangle detected is')\n",
    "            plt.imshow(sliced_image,cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "            for i in range(8): # we rotate here again for all 8 orientations\n",
    "                sliced_image_rotated=rotate(sliced_image,angle=45*i)\n",
    "                sliced_image_rotated=sliced_image_rotated.astype(np.uint8)\n",
    "\n",
    "                #qrCodeDetector = cv2.QRCodeDetector()\n",
    "                #decodedText, points, _ = qrCodeDetector.detectAndDecode(sliced_image)\n",
    "                \n",
    "                zbar_scanner = zbar.Scanner()\n",
    "                sliced_image_rotated= cv2.cvtColor(sliced_image_rotated,cv2.COLOR_BGR2GRAY) #blind deblur returns a grayscale so commented out \n",
    "                decodedText = zbar_scanner.scan(sliced_image_rotated)\n",
    "                print(decodedText)\n",
    "                if len(decodedText) > 0:\n",
    "                    return decodedText\n",
    "                    break\n",
    "                \n",
    "            \n",
    "            '''\n",
    "            #this is the code for showing the rectangles\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            cv2.drawContours(image,[box],0,(36,255,12),30)\n",
    "            '''\n",
    "            \n",
    "        #cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 30)\n",
    "    print(opening.shape)\n",
    "    opening.astype('float')\n",
    "    #plt.title('thresh')\n",
    "    #plt.imshow(thresh,cmap='gray')\n",
    "    #plt.show()\n",
    "    #plt.title('opening')\n",
    "    #plt.imshow(opening,cmap='gray')\n",
    "    #plt.show()\n",
    "    plt.title('qr code not detected')\n",
    "    plt.imshow(image,cmap='gray')\n",
    "    plt.show()\n",
    "    return 0\n",
    "    #cv2.imshow('thresh', thresh)\n",
    "    #cv2.imshow('opening', opening)\n",
    "    #cv2.imshow('image', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CorrectBoxCropping('Datasets/csv_bboxes/*.csv','Datasets/LL_109-110/LL_109-110/NikonD780/*.JPG')\n",
    "csv_109_110=CorrectBoxCropping('Datasets/LL_109-110/LL_109-110/NikonD780/*.JPG','Datasets/csv_bboxes/','deblurred_directory/*.JPG')\n",
    "csv_115_116=CorrectBoxCropping('Datasets/LL_115-116/LL_115-116/NikonD780/*.JPG','Datasets/csv_bboxes/','deblurred_directory/*.JPG')\n",
    "csv_119_120=CorrectBoxCropping('Datasets/LL_119-120/LL_119-120/NikonD7000_18mm/*.JPG','Datasets/csv_bboxes/','deblurred_directory/*.JPG')\n",
    "csv_121_122=CorrectBoxCropping('Datasets/LL_121-122/LL_121-122/NikonD7000_18mm/*.JPG','Datasets/csv_bboxes/','deblurred_directory/*.JPG')\n",
    "csv_125_126=CorrectBoxCropping('Datasets/LL_125-126/LL_125-126/NikonD7000_18mm/*.JPG','Datasets/csv_bboxes/','deblurred_directory/*.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3499,3500,3831,3446,3447,3448,3449,3450,3451,3452,3499,3500,3501,3502,3503,3504,3831,3832,3833,3834,3835,4056,4057\n",
    "#print(csv_109_110[0,:])\n",
    "csv_109_110_copy=np.delete(csv_109_110, (0), axis=0) #deletes that dumb 0,0 in first row. just insert this in regular code\n",
    "print(csv_109_110_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ll_109-110: 0 slices and 26 unenhanced with zbar-py red channel\n",
    "#for ll_115-116: 2 slices and 29 unenhanced with zbar-py red channel\n",
    "#for ll_119-120: 1 slices and 24 unenhanced with zbar-py red channel\n",
    "#for ll_121-122: 5 slices and 14 unenhanced with zbar-py red channel\n",
    "#for ll_125-126: 2 slices and 22 unenhanced with zbar-py red channel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for ll_109-110: 0 slices and 26 unenhanced with zbar-py blue channel\n",
    "#for ll_115-116: 1 slices and 30 unenhanced with zbar-py blue channel\n",
    "#for ll_119-120: 4 slices and 18 unenhanced with zbar-py blue channel\n",
    "#for ll_121-122: 4 slices and 17 unenhanced with zbar-py blue channel\n",
    "#for ll_125-126: 2 slices and 20 unenhanced with zbar-py blue channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ll_109-110: 0 slices and 26 unenhanced with zbar-py\n",
    "#for ll_115-116: 0 slices and 31 unenhanced with zbar-py\n",
    "#for ll_119-120: 0 slices and 25 unenhanced with zbar-py\n",
    "#for ll_121-122: 2 slices and 17 unenhanced with zbar-py\n",
    "#for ll_125-126: 2 slices and 22 unenhanced with zbar-py\n",
    "\n",
    "\n",
    "\n",
    "#for ll_109-110: 0 slices and 26 unenhanced with zbar-py deblur\n",
    "#for ll_115-116: 0 slices and 34 unenhanced with zbar-py deblur\n",
    "#for ll_119-120: 0 slices and 26 unenhanced with zbar-py deblur\n",
    "#for ll_121-122: 2 slices and 17 unenhanced with zbar-py deblur\n",
    "#for ll_125-126: 2 slices and 22 unenhanced with zbar-py deblur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ll_109-110: My rectangles decoded 16, while the annotations only did 5 went up to 20 once i rotated first image and combined\n",
    "#for ll_115-116: My rectangles decoded 5, while the annotations only did 5 went up to 13 once i rotated first image and combined \n",
    "#for ll_119-120: My rectangles decoded 12, while the annotations only did 4 went up to 18 once i rotated first image and combined\n",
    "#for ll_121-122: My rectangles decoded 11, while the annotations only did 5 went up to 13 once i rotated first image and combined\n",
    "#for ll_125-126: My rectangles decoded 12, while the annotations only did 4 up to 14 once i rotated first image and combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take images I could already read blur them and use deblurgan on them, and try to read it with deblurgan. use it on those initial 125 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BlindDeblur(array_passed):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from skimage import color, data, restoration\n",
    "    rng = np.random.default_rng()\n",
    "    astro=color.rgb2gray(array_passed)\n",
    "    #astro = color.rgb2gray(data.astronaut())\n",
    "    from scipy.signal import convolve2d as conv2\n",
    "    psf = np.ones((5, 5)) / 25\n",
    "    astro = conv2(astro, psf, 'same')\n",
    "    astro += 0.1 * astro.std() * rng.standard_normal(astro.shape)\n",
    "\n",
    "    deconvolved, _ = restoration.unsupervised_wiener(astro, psf)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 5),\n",
    "                           sharex=True, sharey=True)\n",
    "\n",
    "    plt.gray()\n",
    "\n",
    "    ax[0].imshow(astro, vmin=deconvolved.min(), vmax=deconvolved.max())\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Data')\n",
    "\n",
    "    ax[1].imshow(deconvolved)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Self tuned restoration')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    return deconvolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
